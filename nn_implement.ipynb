{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'invalid': 'warn', 'over': 'warn', 'under': 'ignore'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.seterr(all='raise', under='warn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationFunction(abc.ABC):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def apply(self, v):\n",
    "        pass\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def derivative(self, v, activated_value):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationNone(ActivationFunction):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def apply(self, v):\n",
    "        return v\n",
    "    \n",
    "    def derivative(self, v, activated_value=True):\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationSigmoid(ActivationFunction):\n",
    "    def __init__(self, x_upper_bound=None, x_lower_bound=None):\n",
    "        self.x_upper_bound = x_upper_bound\n",
    "        self.x_lower_bound = x_lower_bound\n",
    "    \n",
    "    def apply(self, v):\n",
    "        if self.x_upper_bound or self.x_upper_bound:\n",
    "            return 1.0 / (1.0 + np.exp(-v.clip(max=self.x_upper_bound, min=self.x_lower_bound)))\n",
    "        return 1.0 / (1.0 + np.exp(-v))\n",
    "    \n",
    "    def derivative(self, v, activated_value=True):\n",
    "        if not activated_value:\n",
    "            v = self.apply(v)\n",
    "        return v * (1 - v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationRelu(ActivationFunction):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def apply(self, v):\n",
    "        return v.clip(min=0)\n",
    "    \n",
    "    def derivative(self, v, activated_value=True):\n",
    "        if not activated_value:\n",
    "            v = self.apply(v)\n",
    "        return np.where(v>0,1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gd optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDOptimizer(abc.ABC):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def accelerate(self, grads, intercept_grads):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDOptimizerNone(GDOptimizer):\n",
    "    def __init__(self, learning_rate):\n",
    "        self.learning_rate = learning_rate\n",
    "    \n",
    "    def accelerate(self, grads, intercept_grads):\n",
    "        weight_deltas = [learning_rate * grad for grad in grads]\n",
    "        intercept_deltas = [learning_rate * grad for grad in intercept_grads]\n",
    "        return weight_deltas, intercept_deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDOptimizerMomentum(GDOptimizer):\n",
    "    def __init__(self, learning_rate, gamma=0.9):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.gamma = gamma\n",
    "        self.last_weight_deltas = None\n",
    "        self.last_intercept_deltas = None\n",
    "    \n",
    "    def accelerate(self, grads, intercept_grads):\n",
    "        self.last_weight_deltas = \\\n",
    "            [(self.gamma*self.last_weight_deltas[i] if self.last_weight_deltas is not None else 0)\n",
    "             + self.learning_rate*grads[i] for i in range(len(grads))]\n",
    "        self.last_intercept_deltas = \\\n",
    "            [(self.gamma*self.last_intercept_deltas[i] if self.last_intercept_deltas is not None else 0)\n",
    "             + self.learning_rate*intercept_grads[i] for i in range(len(intercept_grads))]\n",
    "        return self.last_weight_deltas, self.last_intercept_deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDOptimizerAdagrad(GDOptimizer):\n",
    "    def __init__(self, learning_rate=0.01, epsilon=1e-8):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDOptimizerAdadelta(GDOptimizer):\n",
    "    def __init__(self, gamma=0.9, epsilon=1e-8):\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDOptimizerRMSprop(GDOptimizer):\n",
    "    def __init__(self, learning_rate=0.001, gamma=0.9, epsilon=1e-8):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNLayer:\n",
    "    def __init__(self, node_count, activation):\n",
    "        self.node_count = node_count\n",
    "        self.activation = activation\n",
    "        self.weights = None\n",
    "        self.intercepts = None\n",
    "    \n",
    "    def init_weights(self, prev_node_count, has_intercepts):\n",
    "        self.weights, self.intercepts = self.xavier_weight_init(prev_node_count, self.node_count, has_intercepts)\n",
    "        \n",
    "    def update_weights(self, weight_deltas, intercept_deltas):\n",
    "        self.weights -= weight_deltas\n",
    "        self.intercepts -= intercept_deltas\n",
    "    \n",
    "    def xavier_weight_init(self, prev_node_count, cur_node_count, has_intercepts):\n",
    "        weights = np.random.randn(prev_node_count, cur_node_count)/np.sqrt(prev_node_count)\n",
    "        intercepts = np.random.randn(cur_node_count)/np.sqrt(prev_node_count) \\\n",
    "            if has_intercepts else np.zeros(cur_node_count)\n",
    "        return weights, intercepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNModel:\n",
    "    def __init__(self, X_size, layers, gd_optimizer, has_interception=True):\n",
    "        self.X_size = X_size\n",
    "        self.has_interception = has_interception\n",
    "        self.model = layers\n",
    "        self.gd_optimizer = gd_optimizer\n",
    "        self.hidden_layer_res = []\n",
    "        self.init_model()\n",
    "    \n",
    "    # initialize model with layers\n",
    "    def init_model(self):\n",
    "        prev_node_count = self.X_size\n",
    "        for layer in self.model:\n",
    "            layer.init_weights(prev_node_count, self.has_interception)\n",
    "            prev_node_count = layer.node_count\n",
    "    \n",
    "    # forward pass, calculate predict value with current model (batch or single)\n",
    "    def model_forward(self, X):\n",
    "        cur_res = X\n",
    "        self.hidden_layer_res.clear()\n",
    "        for layer in self.model:\n",
    "            self.hidden_layer_res.append(cur_res)\n",
    "            cur_res = np.dot(cur_res, layer.weights) + layer.intercepts\n",
    "            cur_res = layer.activation.apply(cur_res)\n",
    "        return cur_res\n",
    "    \n",
    "    # update model with errs (y_predict - y)\n",
    "    def update_model(self, errs):\n",
    "        grads, intercept_grads = self.back_propagation(errs)\n",
    "        weight_deltas, intercept_deltas = self.gd_optimizer.accelerate(grads, intercept_grads)\n",
    "        for i in range(len(self.model)):\n",
    "            self.model[i].update_weights(weight_deltas[i], intercept_deltas[i])\n",
    "    \n",
    "    # back propagation to get gradient (batch or single)\n",
    "    def back_propagation(self, errs):\n",
    "        delta = np.atleast_2d(errs)\n",
    "        reversed_grads = [np.dot(np.atleast_2d(self.hidden_layer_res[-1]).T, delta)/delta.shape[0]]\n",
    "        reversed_grads_intercept = [delta.mean(axis=0)]\n",
    "        for i in range(len(self.model)-2, -1, -1):\n",
    "            delta = np.dot(delta, self.model[i+1].weights.T) \\\n",
    "                    * self.model[i].activation.derivative(self.hidden_layer_res[i+1])\n",
    "            reversed_grads.append(np.dot(np.atleast_2d(self.hidden_layer_res[i]).T, delta)/delta.shape[0])\n",
    "            reversed_grads_intercept.append(delta.mean(axis=0))\n",
    "        \n",
    "        return list(reversed(reversed_grads)), list(reversed(reversed_grads_intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = sklearn.datasets.load_breast_cancer(return_X_y=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_x_org = test_data['data']\n",
    "test_data_y_org = test_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_x_org.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_std = (test_data_x_org - np.mean(test_data_x_org, axis=0)) / np.std(test_data_x_org, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_x = test_data_std[:500]\n",
    "test_data_y = test_data_y_org[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [\n",
    "    NNLayer(20, ActivationSigmoid()),\n",
    "    NNLayer(10, ActivationSigmoid()),\n",
    "    NNLayer(1, ActivationSigmoid()),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = NNModel(test_data_x.shape[1], layers, GDOptimizerMomentum(learning_rate=learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_cost = []\n",
    "all_cost_ce = []\n",
    "for _ in range(rounds):\n",
    "    cost = 0\n",
    "    cost_ce = 0\n",
    "    learning_idx = np.arange(len(test_data_x))\n",
    "    np.random.shuffle(learning_idx)\n",
    "    \n",
    "    for start_idx in range(0, len(test_data_x), batch_size):\n",
    "        data_idx = learning_idx[start_idx : min(start_idx+batch_size,len(test_data_x))]\n",
    "#         data_idx = learning_idx[start_idx]\n",
    "        sample, target = test_data_x[data_idx], test_data_y[data_idx,None]\n",
    "        predict = m.model_forward(sample)\n",
    "        err = predict - target\n",
    "        m.update_model(err)\n",
    "        cost += (err*err).sum()\n",
    "        cost_ce -= (target*np.log(predict)+(1-target)*np.log(1-predict)).sum()\n",
    "    all_cost.append(cost)\n",
    "    all_cost_ce.append(cost_ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xbcc0190>]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xba62210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.plot(all_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data_x = test_data_std[500:]\n",
    "predict_data_y = test_data_y_org[500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_y = []\n",
    "for sample, tgt in zip(predict_data_x, predict_data_y):\n",
    "    pct = m.model_forward(sample)\n",
    "    predict_y.append(pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17,  0],\n",
       "       [ 2, 50]], dtype=int64)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(predict_data_y, [1 if pct > 0.5 else 0 for pct in predict_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1067647858223854e-05"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cost[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
